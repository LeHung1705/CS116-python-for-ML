{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40a1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d0a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = pl.scan_parquet(\"train_data/inference_final_mix.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872469d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load ground truth\n",
    "gt = joblib.load(\"train_data/final_groundtruth_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ecfca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth type: <class 'dict'>\n",
      "Ground truth keys:\n",
      "[2337685, 7934799, 2052333, 6548920, 368770]\n",
      "S·ªë l∆∞·ª£ng kh√°ch h√†ng trong groundtruth: 644970\n"
     ]
    }
   ],
   "source": [
    "# 3. Ki·ªÉm tra c·∫•u tr√∫c c·ªßa ground truth\n",
    "print(\"Ground truth type:\", type(gt))\n",
    "print(\"Ground truth keys:\" if isinstance(gt, dict) else \"Ground truth shape:\")\n",
    "if isinstance(gt, dict):\n",
    "    print(list(gt.keys())[:5])\n",
    "    # L·∫•y ra danh s√°ch customer IDs t·ª´ groundtruth\n",
    "    if isinstance(list(gt.keys())[0], (int, str)):\n",
    "        gt_customers = set(gt.keys())\n",
    "        print(f\"S·ªë l∆∞·ª£ng kh√°ch h√†ng trong groundtruth: {len(gt_customers)}\")\n",
    "else:\n",
    "    print(gt.shape if hasattr(gt, 'shape') else len(gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94855d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference columns: ['customer_id', 'item_id', 'feat1_customer_item_freq', 'feat2_brand_affinity', 'feat2_type_affinity', 'feat3_urgency_score', 'feat3_is_in_window', 'feat4_pop_30d_log', 'feat4_pop_trend', 'feat4_pop_category_rank']\n",
      "\n",
      "Inference shape (estimated): shape: (1, 1)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ len       ‚îÇ\n",
      "‚îÇ ---       ‚îÇ\n",
      "‚îÇ u32       ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ 256561832 ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# 4. Ki·ªÉm tra c·∫•u tr√∫c c·ªßa inference_df\n",
    "print(\"Inference columns:\", inference_df.collect_schema().names()[:10])\n",
    "print(\"\\nInference shape (estimated):\", inference_df.select(pl.len()).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b5c70b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng kh√°ch h√†ng unique trong inference: 2569977\n"
     ]
    }
   ],
   "source": [
    "# 5. L·∫•y danh s√°ch customer_id unique t·ª´ inference_df\n",
    "inference_customers = inference_df.select(\"customer_id\").unique().collect()[\"customer_id\"].to_list()\n",
    "print(f\"S·ªë l∆∞·ª£ng kh√°ch h√†ng unique trong inference: {len(inference_customers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f15858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng kh√°ch h√†ng chung: 509735\n"
     ]
    }
   ],
   "source": [
    "# 6. T√¨m c√°c kh√°ch h√†ng c√≥ trong c·∫£ inference v√† groundtruth\n",
    "inference_customers_set = set(inference_customers)\n",
    "common_customers = list(gt_customers.intersection(inference_customers_set))\n",
    "print(f\"S·ªë l∆∞·ª£ng kh√°ch h√†ng chung: {len(common_customers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c51ae4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ ch·ªçn 15000 kh√°ch h√†ng\n"
     ]
    }
   ],
   "source": [
    "# 7. Ch·ªçn ng·∫´u nhi√™n 15,000 kh√°ch h√†ng t·ª´ danh s√°ch chung\n",
    "import random\n",
    "random.seed(42)  # ƒê·ªÉ reproducible\n",
    "sampled_customers = random.sample(common_customers, 15000)\n",
    "print(f\"ƒê√£ ch·ªçn {len(sampled_customers)} kh√°ch h√†ng\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edbda3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng rows trong inference_df_small: 1,450,359\n",
      "S·ªë l∆∞·ª£ng kh√°ch h√†ng unique: 15000\n"
     ]
    }
   ],
   "source": [
    "# 8. L·ªçc inference_df ƒë·ªÉ ch·ªâ gi·ªØ l·∫°i 15,000 kh√°ch h√†ng ƒë√£ ch·ªçn\n",
    "inference_df_small = inference_df.filter(pl.col(\"customer_id\").is_in(sampled_customers))\n",
    "\n",
    "# Collect ƒë·ªÉ xem k√≠ch th∆∞·ªõc\n",
    "result_size = inference_df_small.select(pl.len()).collect()\n",
    "print(f\"S·ªë l∆∞·ª£ng rows trong inference_df_small: {result_size['len'][0]:,}\")\n",
    "\n",
    "# Ki·ªÉm tra s·ªë l∆∞·ª£ng kh√°ch h√†ng unique\n",
    "unique_customers = inference_df_small.select(\"customer_id\").unique().collect().height\n",
    "print(f\"S·ªë l∆∞·ª£ng kh√°ch h√†ng unique: {unique_customers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98643c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng kh√°ch h√†ng trong groundtruth nh·ªè: 15000\n",
      "V√≠ d·ª• m·ªôt entry trong groundtruth: (4901623, ['6697000000003', '4690000000001'])\n"
     ]
    }
   ],
   "source": [
    "# 9. T·∫°o groundtruth nh·ªè cho 15,000 kh√°ch h√†ng ƒë√£ ch·ªçn\n",
    "gt_small = {customer_id: gt[customer_id] for customer_id in sampled_customers}\n",
    "print(f\"S·ªë l∆∞·ª£ng kh√°ch h√†ng trong groundtruth nh·ªè: {len(gt_small)}\")\n",
    "print(f\"V√≠ d·ª• m·ªôt entry trong groundtruth: {list(gt_small.items())[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718b7b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ l∆∞u inference nh·ªè v√†o: train_data/inference_final_small.parquet\n"
     ]
    }
   ],
   "source": [
    "# 10. L∆∞u inference_df nh·ªè v√†o file parquet\n",
    "output_path_inference = \"train_data/inference_final_small.parquet\"\n",
    "inference_df_small.collect().write_parquet(output_path_inference)\n",
    "print(f\"ƒê√£ l∆∞u inference nh·ªè v√†o: {output_path_inference}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ba2116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ l∆∞u groundtruth nh·ªè v√†o: train_data/groundtruth_small.pkl\n"
     ]
    }
   ],
   "source": [
    "# 11. L∆∞u groundtruth nh·ªè v√†o file pickle\n",
    "output_path_gt = \"train_data/groundtruth_small.pkl\"\n",
    "joblib.dump(gt_small, output_path_gt)\n",
    "print(f\"ƒê√£ l∆∞u groundtruth nh·ªè v√†o: {output_path_gt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e918bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "T√ìM T·∫ÆT K·∫æT QU·∫¢\n",
      "============================================================\n",
      "\n",
      "üìä D·ªÆ LI·ªÜU G·ªêC:\n",
      "   - Inference: 244,356,758 rows (2,442,305 kh√°ch h√†ng)\n",
      "   - Groundtruth: 391,900 kh√°ch h√†ng\n",
      "   - Kh√°ch h√†ng chung: 333,720 kh√°ch h√†ng\n",
      "\n",
      "üì¶ D·ªÆ LI·ªÜU M·ªöI (ƒê√É L∆ØU):\n",
      "   - Inference nh·ªè: 1,450,359 rows (15,000 kh√°ch h√†ng)\n",
      "   - Groundtruth nh·ªè: 15,000 kh√°ch h√†ng\n",
      "   - T·ª∑ l·ªá gi·∫£m: 99.4% (inference)\n",
      "\n",
      "üíæ V·ªä TR√ç FILES:\n",
      "   - train_data/inference_final_small.parquet\n",
      "   - train_data/groundtruth_small.pkl\n",
      "\n",
      "‚úÖ B·∫°n c√≥ th·ªÉ d√πng 2 files n√†y ƒë·ªÉ tune hyperparameters nhanh h∆°n!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 12. Summary\n",
    "print(\"=\" * 60)\n",
    "print(\"T√ìM T·∫ÆT K·∫æT QU·∫¢\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä D·ªÆ LI·ªÜU G·ªêC:\")\n",
    "print(f\"   - Inference: 244,356,758 rows (2,442,305 kh√°ch h√†ng)\")\n",
    "print(f\"   - Groundtruth: 391,900 kh√°ch h√†ng\")\n",
    "print(f\"   - Kh√°ch h√†ng chung: 333,720 kh√°ch h√†ng\")\n",
    "print(f\"\\nüì¶ D·ªÆ LI·ªÜU M·ªöI (ƒê√É L∆ØU):\")\n",
    "print(f\"   - Inference nh·ªè: {result_size['len'][0]:,} rows (15,000 kh√°ch h√†ng)\")\n",
    "print(f\"   - Groundtruth nh·ªè: 15,000 kh√°ch h√†ng\")\n",
    "print(f\"   - T·ª∑ l·ªá gi·∫£m: {(1 - result_size['len'][0] / 244356758) * 100:.1f}% (inference)\")\n",
    "print(f\"\\nüíæ V·ªä TR√ç FILES:\")\n",
    "print(f\"   - {output_path_inference}\")\n",
    "print(f\"   - {output_path_gt}\")\n",
    "print(f\"\\n‚úÖ B·∫°n c√≥ th·ªÉ d√πng 2 files n√†y ƒë·ªÉ tune hyperparameters nhanh h∆°n!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
